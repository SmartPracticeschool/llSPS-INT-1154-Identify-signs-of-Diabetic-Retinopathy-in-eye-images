{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\AK\\\\Desktop\\\\Remort internship 2020\\\\data sets'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"C:/Users/AK/Desktop/Remort internship 2020/data sets\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\AK\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\AK\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\AK\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\AK\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\AK\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\AK\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\AK\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\AK\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\AK\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\AK\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\AK\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\AK\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize the model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Convolution Layer\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AK\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Add Pooling Layer\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Flattening Layer\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AK\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=150, kernel_initializer=\"random_uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Add Hidden Layer\n",
    "model.add(Dense(init=\"random_uniform\",activation=\"relu\",output_dim=150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AK\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=5, kernel_initializer=\"random_uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Add Output layer\n",
    "model.add(Dense(init=\"random_uniform\",activation=\"softmax\",output_dim=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"sgd\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67 images belonging to 5 classes.\n",
      "Found 23 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory('C:/Users/AK/Desktop/Remort internship 2020/data sets/Data set/Training set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                     class_mode = 'categorical')\n",
    "x_test = test_datagen.flow_from_directory('C:/Users/AK/Desktop/Remort internship 2020/data sets/Data set/Testing set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'level 0': 0, 'level 1': 1, 'level 2': 2, 'level 3': 3, 'level 4': 4}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 35s 351ms/step - loss: 0.6672 - accuracy: 0.7552 - val_loss: 2.4197 - val_accuracy: 0.3478\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 0.5972 - accuracy: 0.7771 - val_loss: 2.7741 - val_accuracy: 0.2609\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 31s 308ms/step - loss: 0.4851 - accuracy: 0.8141 - val_loss: 2.6153 - val_accuracy: 0.3043\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 32s 319ms/step - loss: 0.5027 - accuracy: 0.7994 - val_loss: 2.7441 - val_accuracy: 0.3043\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 0.4676 - accuracy: 0.8229 - val_loss: 3.0438 - val_accuracy: 0.3043\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 29s 294ms/step - loss: 0.4020 - accuracy: 0.8288 - val_loss: 3.3291 - val_accuracy: 0.3043\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 31s 310ms/step - loss: 0.4682 - accuracy: 0.8243 - val_loss: 3.2125 - val_accuracy: 0.3043\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 30s 305ms/step - loss: 0.4349 - accuracy: 0.8225 - val_loss: 2.9104 - val_accuracy: 0.2609\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 32s 320ms/step - loss: 0.3928 - accuracy: 0.8408 - val_loss: 3.2750 - val_accuracy: 0.2174\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 30s 301ms/step - loss: 0.4401 - accuracy: 0.8288 - val_loss: 3.0291 - val_accuracy: 0.2609\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 32s 322ms/step - loss: 0.3647 - accuracy: 0.8500 - val_loss: 3.5322 - val_accuracy: 0.2174\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 33s 326ms/step - loss: 0.3367 - accuracy: 0.8466 - val_loss: 3.5300 - val_accuracy: 0.2174\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 30s 298ms/step - loss: 0.3470 - accuracy: 0.8386 - val_loss: 3.5296 - val_accuracy: 0.3478\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 33s 330ms/step - loss: 0.3209 - accuracy: 0.8482 - val_loss: 3.5446 - val_accuracy: 0.3478\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 31s 313ms/step - loss: 0.3113 - accuracy: 0.8618 - val_loss: 3.6146 - val_accuracy: 0.3913\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 30s 295ms/step - loss: 0.2912 - accuracy: 0.8591 - val_loss: 3.5040 - val_accuracy: 0.3478\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 0.2840 - accuracy: 0.8613 - val_loss: 3.6472 - val_accuracy: 0.3913\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 32s 317ms/step - loss: 0.2571 - accuracy: 0.8582 - val_loss: 4.1892 - val_accuracy: 0.3043\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 0.2978 - accuracy: 0.8631 - val_loss: 3.8578 - val_accuracy: 0.3478\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 29s 294ms/step - loss: 0.3013 - accuracy: 0.8523 - val_loss: 3.7512 - val_accuracy: 0.3478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e944b24548>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# model.fit_generator(x_train,samples_per_epoch = 80,epochs=25,validation_data=x_test,nb_val_samples=90)\n",
    "model.fit_generator(x_train,\n",
    "                          steps_per_epoch = 100,\n",
    "                          epochs = 20,\n",
    "                        validation_data = x_test,\n",
    "                          validation_steps = 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"dr.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\ak\\anaconda3\\lib\\site-packages (4.2.0.34)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\ak\\anaconda3\\lib\\site-packages (from opencv-python) (1.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('dr.h5')\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#                         optimizer='adam',\n",
    "#                         metrics=['accuracy'])\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "def detect(frame):\n",
    "    try:\n",
    "        img = resize(frame,(64,64))\n",
    "        img = np.expand_dims(img,axis=0)\n",
    "        if(np.max(img)>1):\n",
    "            img = img/255.0\n",
    "        prediction = model.predict(img)\n",
    "        print(prediction)\n",
    "        prediction = model.predict_classes(img)\n",
    "        print(prediction)\n",
    "    except AttributeError:\n",
    "        print(\"shape not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.84459844e-22 1.81338289e-09 8.91918242e-01 1.08081296e-01\n",
      "  4.20073746e-07]]\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread(\"Diabetic5.jpg\")\n",
    "data = detect(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
